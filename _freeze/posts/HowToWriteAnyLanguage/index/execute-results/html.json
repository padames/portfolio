{
  "hash": "98039161a53166aec396754683fa26ba",
  "result": {
    "markdown": "---\ntitle: \"How to process any text with Unicode\"\nauthor: \"Pablo Adames\"\ndate: \"2025-01-21\"\ncategories: [text, C++, unicode, Rust, R]\nbibliography: references.bib\ncsl: elsevier-vancouver.csl\nformat: html\nknitr:\n  opts_chunk: \n    collapse: true\n    comment: \"#>\"\n---\n\n\n## Text is everywhere\n\nChatbots, web pages, and screen monitors display information on cell phones, home and office computers, airports, bus and train stations. The text used in these scenarios enables clear communication. Text is not impeded by sound or obstructed by environmental noise and can deliver impactful meaning through semantically dense words reinforced by context and other visual or aural signals.\n\nText and human language are technologies developed to build and transmit culture. As such, they have a fundamental role in sustaining our civilization.\n\n![Image from https://neuroflash.com/blog/automatic-text-editor-online/](https://neuroflash.com/wp-content/uploads/2022/09/feature-image-automatic-text-editor-online.jpg)\n\n\n## What is text anyway? \n\nIn the spirit of getting down to the essence of this blog post, let's constrain the answer to the world of computers and computer languages. Computer languages tell computers what to do when they see data.\n\nComputer programming starts by writing instructions in a text editor. The characters used to form those instructions are called the ASCII characters. The instructions should be easy to follow by humans, thus the limited number of characters in the ASCII set simplifies the variety of possible keywords of the language. These instructions are transformed into machine-readable code before the computer can execute them.\n\n\n## How do we use text?\n\nMost computer languages use written English as the source of their instructions and even for their semantic meaning. The programming languages that claim to be declarative are said to \"read like English.\"\n\nEverybody benefits from this convention because it lowers the barrier to entry to computer programming as a discipline. It attempts to insulate the program as an artifact from the culture of the programmer. However, bias will always favour the English-speaking programmer who knows how English reads.\n\nAccepting the historical facts, let's dive into the ASCII character set. Its purpose is for programmers to encode rules that control the computer as it consumes input and produces output. We call these rules the program's logic.\n\nThe input to and output from the program we will call data. Digital computers natively process only zeros and ones. Any computer data, including text, must be transformed into a sequence of these two values.\n\n\n## Entering text encoding\n\nText as data is a complex subject. The complexity comes from text originating in human communication within rich and diverse cultural contexts.  Tradition, convention, identity, and art influence the glyphs and alphabets used to articulate words, sentences and ultimately, ideas in human languages that are as diverse as the human groups that produce them. \n\nI will quote directly from the Unicode standard definition \\#51 @uni16:emoji.\n  \n>Unicode is the foundation for text in all modern software: it‚Äôs how all mobile phones, desktops, and other computers represent the text of every language.\n\nThe common UNICODE text encoding used to write source code in modern computer languages is UTF-8, it is the encoding used to store the text of almost the entirety of the web pages of the Internet.\nUTF stands for the Unicode Transformation Format @enwiki:1268238400_.\nThis is a super set of the ASCII character set used in the first computer languages like COBOL, FORTRAN and BASIC.\n\n![Figure from @convertcodes:encodeformats showing ranges of code points and how they are encoded in UTF-8 form](codePointToUTF8Conversion.png)\n\nIn the above table the code values or code points are defined by the range of values between the values in the first two columns. \nThe corresponding UTF-8 form has a variable number of bytes.\nHow many bytes is encoded by the number of consecutive ones in the most significant digits of the first byte in a byte sequence: none means the encoded character fits in one byte.\nOne means the byte is part of a multi-byte sequence.\nTwo means the character is encoded in two bytes.\nThree and four equivalently.\nThis means that there is no need for escape sequences to mark the boundary of a single encoded character when there is a sequence of more than one character.\n\nUTF offers three forms to encode each of the 1,112,064 valid Unicode scalar values: UTF-8, UTF-16 and UTF-32.\nThese Unicode values are also called code points, in base-16 they are the scalar values defined by the following two sequences: U+0000 to U+D7FF and U+E000 to U+10FFFF.\nThe first 128 correspond to the original ASCII.\n\nEach encoding form maps the Unicode code points to unique code unit sequences @uni16:encodingforms.\nIn particular, the larger UNICODE code points may need multiple single code units if using the code form UTF-8.\nConversely they may fit into a single code unit if encoded in the form UTF-32.\nThis happens because the width of the smallest code unit is 8, 16, or 32 bits respectively for each of the forms.\n\nThe selection of a encoding form to map code points to code units forces a trade off between space and complexity.\nUTF-8 is very efficient for handling the smaller UNICODE values while it is complex to handle the higher ones, \nConversely, UTF-32 is wasteful for storing the smaller values but simple for the higher ones.\n\nIn general, UTF-8 is the most suitable option for web pages and computer programs.\nThe reason is only pragmatic because it makes the web engines and text editors and parsers work well when consuming most html, Javascript, and general purpose computer languages.\n\n### More definitions\n\nWe are not done with definitions yet.\nSome additional considerations are necessary to process text correctly, for this a detailed reading of the Unicode standard is advised @uni16:texthandling.\nI will focus first on the difference between characters and glyphs. \n\nA character is an abstract representation of a concrete mark made on paper or rendered to a computer screen, a so-called glyph.\nThe character abstraction is expressed as a UNICODE value.\n\n\nThe standard defines how to represent and how to identify a text character as a code point, however it does not provide rules for determining what a valid text element is because that depends on what the context is.\nExamples of context are capitalization for a title in English text, or the brake down of long sequences of characters at the end of text lines.\n\nA text unit, thus is a valid sequence of one or more encoded text chraracters @uni16:texthandling.\n\n\n\n## Practical character boundary examples\n\nI will present examples of character boundary identification in different computer languages.\nWe will limit the scope to identifying emoticons mixed in with text for rendering text using UTF-8 encoding as most modern editors and terminals would do.\n\n\n### C++\n\nComing soon...\n\n### Rust\n\nIn Rust I used the crate `emojis` from the public registry. \nA `crate` is a module in Rust. \nFor more details read the free [cargo online book](https://doc.rust-lang.org/cargo/index.html).\n\nThe code creates a Rust String by concatenating String slices.\nThen it  uses the magic of the String function `chars` to find the character boundaries and to print them one by one.\nThe 'magic' comes from the fact that some of these characters have multi-unit representations in UTF-8, the default UNICODE form used by the Rust String data type. \n\nIn other words the function has to parse the byte sequence and using the UTF-8 deconding rules find whole characters, using the rules explained below Figure 1. \nOnce the base 16 UNICODE code points are found a rendering function has to find them in a table  and create the matching glyph on the terminal.\n\n```rust\nextern crate emojis;\n\n\nfn main() {\n    let fruit: Vec<_> = emojis::Group::FoodAndDrink.emojis().map(|e| e.as_str()).take(5).collect();\n    assert_eq!(fruit, [\"üçá\", \"üçà\", \"üçâ\", \"üçä\", \"üçã\"]);\n    \n    let test_string = String::from(fruit[0]);\n    let long_fruity_string = \"Hello\".to_owned() + &test_string + \", \" + fruit[1]; \n    \n    // println!(\"Hello, {}!\", long_fruity_string);\n\n    for letter in long_fruity_string.chars() {\n        println!(\"{letter}\");\n    }\n}\n```\nThe output:\n\n```\n$ cargo run\n    Finished dev [unoptimized + debuginfo] target(s) in 0.01s\n     Running `target/debug/word_boundary`\nH\ne\nl\nl\no\nüçá\n,\n \nüçà\n```\n\nI can show the byte sequence in hexadecimal by adding the following lines of code:\n\n```rust\n\n\n```\n\n\n### Python\n\nComing soon...\n\n### R\n\nR has the `emoji` package. After a short exploration of its manual @r-package:emoji it is possible to print the characters of a sentence using the fruit emojis by identifying their  boundaries boundaries seamlessly.\n\n```r\ninstall.packages(\"emoji\")\nlibrary(\"emoji\")\nfruit <- emojis[ emojis$name %in% c(\"grapes\", \"watermelon\", \"melon\", \"lemon\", \"tangerine\"),]$emoji\ntest_string <- fruit[1]\nlong_fruity_string <- paste(\"Hello\", test_string, \", \", fruit[2] )\n#cat(long_fruity_string) # uncomment to print to screen\nstrsplit(x = long_fruity_string, split = \"\")[[1]]\n```\n\nProduces the output\n```\n [1] \"H\"  \"e\"  \"l\"  \"l\"  \"o\"  \" \"  \"üçá\" \" \"  \",\"  \" \"  \" \"  \"üçà\"\n ```\n\n## Conclusion\n\nComing soon...\n\n\n\n### References\n\n::: {#refs}\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}